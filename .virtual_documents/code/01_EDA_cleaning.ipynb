# Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import os





# ppp1 = pd.read_csv('../data/public_up_to_150k_1_230930.csv')
path = '../data/'
dir_list = os.listdir(path)[:-1] # Exclude the data dict
print(dir_list)


loans_1 = pd.read_csv(path + dir_list[0])
loans_2 = pd.read_csv(path + dir_list[1])
ppp = pd.concat([loans_1, loans_2])


ppp.shape


ppp.columns


print(ppp['LoanStatus'].value_counts())
print(np.sum(ppp['LoanStatus'].isna())) # no nulls


# Baseline model and class imbalance
paid_frac = np.sum(ppp['LoanStatus'] == 'Paid in Full') / ppp.shape[0]
forgiven_frac = np.sum(ppp['LoanStatus'] == 'Charged Off') / ppp.shape[0]
ex4_frac = np.sum(ppp['LoanStatus'] == 'Exemption 4') / ppp.shape[0]
print(f'Paid in full: {round(paid_frac, 3)}')
print(f'Charged Off: {round(forgiven_frac, 3)}')
print(f'Exemption 4: {round(ex4_frac, 3)}')








# type check
ppp['SBAOfficeCode'] = ppp['SBAOfficeCode'].astype(int)


np.sum(ppp['LoanStatusDate'].isna()) / ppp['LoanStatusDate'].size





np.sum(ppp['UndisbursedAmount'] > 0)


ppp[ppp['UndisbursedAmount'] > 0][['UndisbursedAmount', 'CurrentApprovalAmount']]





ppp['RuralUrbanIndicator'].value_counts()


np.sum(ppp['RuralUrbanIndicator'].isna())


ppp['HubzoneIndicator'].value_counts()


np.sum(ppp['BusinessAgeDescription'].isna())


np.sum(ppp['ProjectCountyName'].isna())





np.sum(ppp['CD'].isna())





ppp['CD'] = ppp['CD'].where(ppp['CD'].notna(), 'unrecorded')
np.sum(ppp['CD'].isna())


np.sum(ppp['JobsReported'].isna()) # All businesses report number of jobs (business size)


ppp['NAICSCode'].dtypes


np.sum(ppp['NAICSCode'].isna())





# temp_ppp = ppp


ppp['NAICSCode'] = ppp['NAICSCode'].where(ppp['NAICSCode'].notna(), 0)
np.sum(ppp['NAICSCode'].isna())


temp = ppp['NAICSCode'].astype(int).astype(str).replace(to_replace='0', value='000000')
np.sum(temp == '000000')


ppp['NAICSCode'] = temp


ppp['NAICSCode'].dtypes


np.sum(ppp[['Race', 'Ethnicity', 'Gender', 'Veteran']].isna(), axis=0)





np.sum(ppp[['UTILITIES_PROCEED', 'PAYROLL_PROCEED', 'MORTGAGE_INTEREST_PROCEED', 'RENT_PROCEED', 'REFINANCE_EIDL_PROCEED', 'HEALTH_CARE_PROCEED', 'DEBT_INTEREST_PROCEED']].isna(), axis=0)


# fill nulls as zero
temp = ppp[['UTILITIES_PROCEED', 'PAYROLL_PROCEED', 'MORTGAGE_INTEREST_PROCEED', 'RENT_PROCEED', 'REFINANCE_EIDL_PROCEED', 'HEALTH_CARE_PROCEED', 'DEBT_INTEREST_PROCEED']]

temp = temp.replace(to_replace=np.nan, value=0.0)
np.sum(temp.isna(), axis=0)

# df = ppp.drop(['UTILITIES_PROCEED', 'PAYROLL_PROCEED', 'MORTGAGE_INTEREST_PROCEED', 'RENT_PROCEED', 'REFINANCE_EIDL_PROCEED', 'HEALTH_CARE_PROCEED', 'DEBT_INTEREST_PROCEED']).merge(temp, how='left')
# df.head(10)


temp_df = ppp.drop(columns=['UTILITIES_PROCEED', 'PAYROLL_PROCEED', 'MORTGAGE_INTEREST_PROCEED', 'RENT_PROCEED', 'REFINANCE_EIDL_PROCEED', 'HEALTH_CARE_PROCEED', 'DEBT_INTEREST_PROCEED'])


temp_df['UTILITIES_PROCEED'] = temp['UTILITIES_PROCEED']


# temp_df.shape
# temp_df['PAYROLL_PROCEED'] = temp['PAYROLL_PROCEED']
# temp_df.shape

for proceed in ['UTILITIES_PROCEED', 'PAYROLL_PROCEED', 'MORTGAGE_INTEREST_PROCEED', 'RENT_PROCEED', 'REFINANCE_EIDL_PROCEED', 'HEALTH_CARE_PROCEED', 'DEBT_INTEREST_PROCEED']:
    ppp[proceed] = temp[proceed]

ppp.shape





np.sum(ppp[['BusinessType', 'OriginatingLenderLocationID']].isna(), axis=0)


# Handle 163 null business type
bt_temp = ppp['BusinessType'].replace(to_replace=np.nan, value='unrecorded')
np.sum(bt_temp.isna())

ppp['BusinessType'] = bt_temp


ppp['OriginatingLenderLocationID'] = ppp['OriginatingLenderLocationID'].astype(int).astype(str)





# Choose features we believe will be most predictive
drop_features = ['LoanNumber', 'DateApproved', 'BorrowerName', 'BorrowerAddress', 'LoanStatusDate', 'UndisbursedAmount', 'ServicingLenderName', 'ServicingLenderAddress', 'ProjectCity', 'ProjectCountyName', 'ProjectState', 'ProjectZip', 'OriginatingLender', 'OriginatingLenderCity', 'OriginatingLenderState', 'ForgivenessAmount', 'ForgivenessDate']
temp_dropped = ppp.drop(columns=drop_features)


temp_dropped.columns


ppp = temp_dropped


ppp.columns





np.sum(ppp.isna(), axis=0)


ppp = ppp.drop(columns=['FranchiseName', 'NonProfit'])
np.sum(ppp.isna(), axis=0)


# drop rows with null borrower city and zip

temp = ppp[ppp['BorrowerCity'].notna()]
ppp = temp
np.sum(ppp.isna(), axis=0)





ppp['LoanStatus'] = ppp['LoanStatus'].replace({'Paid in Full' : 1, 'Charged Off' : 0, 'Exemption 4' : 0})

ppp['LoanStatus'].value_counts(normalize=True)








ppp.to_csv('../data/cleaned_1and2_reduced.csv', index=False)



